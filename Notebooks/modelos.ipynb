{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.48\n",
      "recall_score 0.2909090909090909\n",
      "precision_score 0.5517241379310345\n",
      "roc_auc_score 0.5010101010101011\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "\n",
    "# Leer el DataFrame desde un archivo CSV\n",
    "df_historico = pd.read_csv('../Raw_Datasets/datos_historicos_deportes.csv')\n",
    "\n",
    "# Características (features) del modelo\n",
    "X = df_historico.drop('Deporte', axis=1)\n",
    "y = df_historico['Deporte']\n",
    "\n",
    "# Dividir los datos en un conjunto de entrenamiento (80%) y un conjunto de prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "parameters = {\"n_estimators\":[50,100,150],\n",
    "              \"max_depth\":[2,3,4],\n",
    "              \"criterion\": ['gini', 'entropy'],\n",
    "              \"min_samples_split\": [5,8],\n",
    "              \"min_samples_leaf\": [2,3],\n",
    "              \"max_features\": [1,2]\n",
    "}\n",
    "\n",
    "dtr_gs = GridSearchCV(model, parameters, cv=5, scoring=\"accuracy\", )\n",
    "\n",
    "\n",
    "dtr_gs.fit(X_train, y_train)\n",
    "\n",
    "dtr_gs.best_estimator_\n",
    "\n",
    "y_pred = dtr_gs.best_estimator_.predict(X_test)\n",
    "\n",
    "print(\"accuracy_score\", accuracy_score(y_test, y_pred))\n",
    "print(\"recall_score\", recall_score(y_test, y_pred))\n",
    "print(\"precision_score\", precision_score(y_test, y_pred))\n",
    "print(\"roc_auc_score\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Precisión del modelo en el conjunto de prueba: 0.515\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Resto del código...\n",
    "\n",
    "# Aplicar SMOTE para sobre-muestrear las clases minoritarias\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Crear el modelo RandomForestClassifier\n",
    "modelo = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definir la rejilla de hiperparámetros a buscar\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 100],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros con validación cruzada\n",
    "grid_search = GridSearchCV(estimator=modelo, param_grid=param_grid,)\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Obtener los mejores hiperparámetros encontrados\n",
    "mejores_hiperparametros = grid_search.best_params_\n",
    "print(\"Mejores hiperparámetros:\", mejores_hiperparametros)\n",
    "\n",
    "# Entrenar el modelo con los mejores hiperparámetros en todo el conjunto de entrenamiento\n",
    "modelo_optimizado = RandomForestClassifier(**mejores_hiperparametros, random_state=42)\n",
    "modelo_optimizado.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba con el modelo optimizado\n",
    "predicciones = modelo_optimizado.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo en el conjunto de prueba\n",
    "precision = accuracy_score(y_test, predicciones)\n",
    "print(\"Precisión del modelo en el conjunto de prueba:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.525\n",
      "accuracy_score 0.525\n",
      "precision_score 0.5842696629213483\n",
      "roc_auc_score 0.5308080808080808\n",
      "Recall promedio (macro): 0.5308080808080808\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score,recall_score,precision_score\n",
    "\n",
    "# Leer el DataFrame desde un archivo CSV\n",
    "df_historico = pd.read_csv('../Raw_Datasets/datos_historicos_deportes.csv')\n",
    "\n",
    "# Características (features) del modelo\n",
    "X = df_historico.drop('Deporte', axis=1)\n",
    "# Etiqueta del modelo: Deporte practicado\n",
    "y = df_historico['Deporte']\n",
    "\n",
    "# Dividir los datos en un conjunto de entrenamiento (80%) y un conjunto de prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo Random Forest\n",
    "modelo = RandomForestClassifier(random_state=42)\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Realizar la predicción del modelo con los datos de prueba\n",
    "predicciones = modelo.predict(X_test)\n",
    "\n",
    "precision = accuracy_score(y_test, predicciones)\n",
    "print(\"Precisión del modelo:\", precision)\n",
    "\n",
    "\n",
    "print(\"accuracy_score\", accuracy_score(y_test, predicciones))\n",
    "# print(\"recall_score\", recall_score(y_test, predicciones))\n",
    "print(\"precision_score\", precision_score(y_test, predicciones))\n",
    "print(\"roc_auc_score\", roc_auc_score(y_test, predicciones))\n",
    "\n",
    "\n",
    "recall_macro = recall_score(y_test, predicciones, average='macro')\n",
    "print(\"Recall promedio (macro):\", recall_macro)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "folder = \"modelos_en_pkl\"\n",
    "\n",
    "# Asegúrate de que la carpeta exista. Si no existe, créala.\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "# Ruta completa del archivo donde se guardará el modelo\n",
    "filename = os.path.join(folder, \"Randomforest.pkl\")\n",
    "\n",
    "# Guardar el modelo en el archivo\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  RandomForestClassifier Con datos de el clima..   NO VALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de969\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2 features, but RandomForestClassifier is expecting 72 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 105\u001b[0m\n\u001b[0;32m    102\u001b[0m     datos_instalaciones\u001b[39m.\u001b[39mextend(cargar_datos_instalaciones(nombre_archivo_sitios, tipo))\n\u001b[0;32m    104\u001b[0m \u001b[39m# Obtener recomendaciones de deportes utilizando el modelo de machine learning\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m recomendaciones_deportes_modelo \u001b[39m=\u001b[39m obtener_recomendaciones_deportes_modelo(\n\u001b[0;32m    106\u001b[0m     datos_clima, etiquetas_ola_calor, datos_instalaciones\n\u001b[0;32m    107\u001b[0m )\n\u001b[0;32m    109\u001b[0m \u001b[39m# Imprime las recomendaciones del modelo\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRecomendaciones de deportes (modelo):\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[33], line 56\u001b[0m, in \u001b[0;36mobtener_recomendaciones_deportes_modelo\u001b[1;34m(datos_clima, etiquetas_ola_calor, datos_instalaciones)\u001b[0m\n\u001b[0;32m     53\u001b[0m ola_de_calor_actual \u001b[39m=\u001b[39m etiquetas_ola_calor[\u001b[39m0\u001b[39m]\n\u001b[0;32m     55\u001b[0m \u001b[39m# Realizar la predicción del modelo con los datos actuales\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m prediccion_actual \u001b[39m=\u001b[39m modelo\u001b[39m.\u001b[39;49mpredict([[temperatura_actual, ola_de_calor_actual]])\n\u001b[0;32m     58\u001b[0m recomendaciones \u001b[39m=\u001b[39m []\n\u001b[0;32m     60\u001b[0m \u001b[39mif\u001b[39;00m prediccion_actual[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     61\u001b[0m     \u001b[39m# Si el modelo predice que hay que evitar deportes, entonces:\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[39m# Recomendar actividades en centros de salud si tiene problemas de salud\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    803\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 823\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    825\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    826\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    863\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    864\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    867\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    868\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    598\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 599\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    600\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    627\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2 features, but RandomForestClassifier is expecting 72 features as input."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Función para leer datos meteorológicos desde un archivo JSON\n",
    "def leer_datos_meteorologicos(nombre_archivo):\n",
    "    with open(nombre_archivo, 'r') as archivo:\n",
    "        datos = json.load(archivo)\n",
    "    return datos\n",
    "\n",
    "# Función para etiquetar la presencia de una ola de calor basada en datos climáticos\n",
    "def etiquetar_ola_de_calor(datos_clima, umbral_temperatura):\n",
    "    etiquetas = []\n",
    "    for registro in datos_clima['data']['list']:\n",
    "        temperatura = registro['main']['temp']\n",
    "        if temperatura > umbral_temperatura:\n",
    "            etiquetas.append(1)  # Hay ola de calor\n",
    "        else:\n",
    "            etiquetas.append(0)  # No hay ola de calor\n",
    "    return etiquetas\n",
    "\n",
    "# Función para cargar datos de instalaciones desde un archivo CSV y filtrar por tipo de instalación\n",
    "def cargar_datos_instalaciones(nombre_archivo_csv, tipo_instalacion):\n",
    "    csv.field_size_limit(500 * 1024)\n",
    "    datos_instalaciones = []\n",
    "    with open(nombre_archivo_csv, 'r', encoding='utf-8', newline='') as archivo_csv:\n",
    "        lector_csv = csv.DictReader(archivo_csv)\n",
    "        for fila in lector_csv:\n",
    "            if fila['TIPO'] == tipo_instalacion:\n",
    "                datos_instalaciones.append(fila)\n",
    "    return datos_instalaciones\n",
    "\n",
    "# Función para obtener recomendaciones de deportes utilizando el modelo de machine learning\n",
    "def obtener_recomendaciones_deportes_modelo(datos_clima, etiquetas_ola_calor, datos_instalaciones):\n",
    "    # Obtener los datos históricos de recomendaciones de deportes\n",
    "    # Aquí asumimos que tienes un archivo CSV llamado 'datos_historicos_deportes.csv'\n",
    "    # que contiene datos históricos con columnas como 'Temperatura', 'OlaDeCalor', 'TipoInstalacion' y 'Recomendacion'\n",
    "    df_historico = pd.read_csv('../Raw_Datasets/datos_historicos_deportes.csv')\n",
    "\n",
    "    # Características (features) del modelo: Temperatura y Ola de calor (1 si hay ola de calor, 0 si no)\n",
    "    X = df_historico.drop('Deporte', axis=1)\n",
    "\n",
    "    # Etiquetas del modelo: Recomendación de deporte\n",
    "    y = df_historico['Deporte'].values\n",
    "\n",
    "    # Entrenar el modelo Random Forest\n",
    "    modelo = RandomForestClassifier(random_state=42)\n",
    "    modelo.fit(X, y)\n",
    "\n",
    "    # Obtener los valores actuales de Temperatura y Ola de calor\n",
    "    temperatura_actual = datos_clima['data']['list'][0]['main']['temp']\n",
    "    ola_de_calor_actual = etiquetas_ola_calor[0]\n",
    "\n",
    "    # Realizar la predicción del modelo con los datos actuales\n",
    "    prediccion_actual = modelo.predict([[temperatura_actual, ola_de_calor_actual]])\n",
    "\n",
    "    recomendaciones = []\n",
    "\n",
    "    if prediccion_actual[0] == 1:\n",
    "        # Si el modelo predice que hay que evitar deportes, entonces:\n",
    "        # Recomendar actividades en centros de salud si tiene problemas de salud\n",
    "        if tiene_problemas_salud:\n",
    "            recomendaciones.extend(obtener_recomendaciones_centros_salud(datos_instalaciones))\n",
    "    else:\n",
    "        # Si el modelo predice que se pueden hacer deportes, entonces:\n",
    "        # Recomendar actividades al aire libre en parques y jardines\n",
    "        recomendaciones.extend(obtener_recomendaciones_parques(datos_instalaciones))\n",
    "\n",
    "    return recomendaciones\n",
    "\n",
    "# Función para obtener recomendaciones específicas para parques y jardines\n",
    "def obtener_recomendaciones_parques(instalaciones):\n",
    "    recomendaciones_parques = []\n",
    "    for instalacion in instalaciones:\n",
    "        if instalacion['TIPO'] == 'parque':\n",
    "            recomendaciones_parques.append(f\"Hacer ejercicio en el parque: {instalacion['NOMBRE']} ({instalacion['DIRECCION']})\")\n",
    "    return recomendaciones_parques\n",
    "\n",
    "# Función para obtener recomendaciones específicas para centros de salud\n",
    "def obtener_recomendaciones_centros_salud(instalaciones):\n",
    "    recomendaciones_centros_salud = []\n",
    "    for instalacion in instalaciones:\n",
    "        if instalacion['TIPO'].lower() == 'centro_salud' and tiene_problemas_salud:\n",
    "            recomendaciones_centros_salud.append(f\"Realizar actividad en centro de salud: {instalacion['NOMBRE']} ({instalacion['DIRECCION']})\")\n",
    "    return recomendaciones_centros_salud\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nombre_archivo_json = \"../Raw_Datasets/Trabajado/tiempo.json\"  # Reemplaza con el nombre de tu archivo JSON\n",
    "    nombre_archivo_sitios = \"../Raw_Datasets/items_Giacomo/items.csv\"  # Reemplaza con el nombre de tu archivo CSV de sitios (piscinas, parques y polideportivos)\n",
    "\n",
    "    umbral_temperatura_ola_calor = 30.0  # Reemplaza con el umbral de temperatura para definir una ola de calor\n",
    "    tiene_problemas_salud = True  # Reemplaza con True si el usuario tiene problemas de salud, False si no\n",
    "\n",
    "    datos_clima = leer_datos_meteorologicos(nombre_archivo_json)\n",
    "    etiquetas_ola_calor = etiquetar_ola_de_calor(datos_clima, umbral_temperatura_ola_calor)\n",
    "\n",
    "    tipos_instalaciones_deportivas = {'PISCINA', 'ZONA VERDE', 'SENDA', 'CENTRO DE SALUD'}\n",
    "\n",
    "    datos_instalaciones = []\n",
    "    for tipo in tipos_instalaciones_deportivas:\n",
    "        datos_instalaciones.extend(cargar_datos_instalaciones(nombre_archivo_sitios, tipo))\n",
    "\n",
    "    # Obtener recomendaciones de deportes utilizando el modelo de machine learning\n",
    "    recomendaciones_deportes_modelo = obtener_recomendaciones_deportes_modelo(\n",
    "        datos_clima, etiquetas_ola_calor, datos_instalaciones\n",
    "    )\n",
    "\n",
    "    # Imprime las recomendaciones del modelo\n",
    "    print(\"Recomendaciones de deportes (modelo):\")\n",
    "    for deporte in recomendaciones_deportes_modelo:\n",
    "        print(deporte)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RadientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.495\n",
      "recall_score: 0.43636363636363634\n",
      "precision_score: 0.5517241379310345\n",
      "roc_auc_score: 0.5015151515151515\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Leer el DataFrame desde un archivo CSV\n",
    "df_historico = pd.read_csv('../Raw_Datasets/datos_historicos_deportes.csv')\n",
    "\n",
    "# Características (features) del modelo\n",
    "X = df_historico.drop('Deporte', axis=1)\n",
    "y = df_historico['Deporte']\n",
    "\n",
    "\n",
    "# Dividir los datos en un conjunto de entrenamiento (80%) y un conjunto de prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\": [50, 100, 150],\n",
    "    \"learning_rate\": [0.1, 0.05, 0.01],\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "}\n",
    "\n",
    "dtr_gs = GridSearchCV(model, parameters, cv=5, scoring=\"accuracy\")\n",
    "dtr_gs.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtr_gs.best_estimator_.predict(X_test)\n",
    "\n",
    "print(\"accuracy_score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"recall_score:\", recall_score(y_test, y_pred,))\n",
    "print(\"precision_score:\", precision_score(y_test, y_pred,))\n",
    "print(\"roc_auc_score:\", roc_auc_score(y_test, y_pred,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "# Supongamos que quieres guardar el modelo en la carpeta \"modelos\"\n",
    "# dentro del directorio actual\n",
    "folder = \"../modelos_en_pkl\"\n",
    "\n",
    "# Asegúrate de que la carpeta exista. Si no existe, créala.\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "# Ruta completa del archivo donde se guardará el modelo\n",
    "filename = os.path.join(folder, \"GradientBoosting.pkl\")\n",
    "\n",
    "# Guardar el modelo en el archivo\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Leer el DataFrame desde un archivo CSV\n",
    "df_historico = pd.read_csv('../Raw_Datasets/datos_historicos_deportes.csv')\n",
    "\n",
    "# Características (features) del modelo\n",
    "X = df_historico.drop('Deporte', axis=1)\n",
    "y = df_historico['Deporte']\n",
    "\n",
    "# Dividir los datos en un conjunto de entrenamiento (80%) y un conjunto de prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el modelo SVM con kernel lineal\n",
    "modelo = OneVsOneClassifier(SVC(kernel='linear', random_state=42))\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Calcular las métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "# roc_auc = roc_auc_score(y_test, y_pred, multi_class='ovo')\n",
    "\n",
    "# Imprimir las métricas de evaluación\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "# print(\"ROC AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"modelos_en_pkl\"\n",
    "\n",
    "# Asegúrate de que la carpeta exista. Si no existe, créala.\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "# Ruta completa del archivo donde se guardará el modelo\n",
    "filename = os.path.join(folder, \"svc.pkl\")\n",
    "\n",
    "# Guardar el modelo en el archivo\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_train: (800, 72)\n",
      "Forma de X_test: (200, 72)\n",
      "Forma de y_train: (800,)\n",
      "Forma de y_test: (200,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "# Leer el DataFrame desde un archivo CSV\n",
    "df_historico = pd.read_csv('../Raw_Datasets/datos_historicos_deportes.csv')\n",
    "\n",
    "# Características (features) del modelo\n",
    "X = df_historico.drop('Deporte', axis=1)\n",
    "y = df_historico['Deporte']\n",
    "\n",
    "# Dividir los datos en un conjunto de entrenamiento (80%) y un conjunto de prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verificar las formas de los datos para asegurarse de que tengan la misma cantidad de características\n",
    "print(\"Forma de X_train:\", X_train.shape)\n",
    "print(\"Forma de X_test:\", X_test.shape)\n",
    "print(\"Forma de y_train:\", y_train.shape)\n",
    "print(\"Forma de y_test:\", y_test.shape)\n",
    "\n",
    "# Crear el modelo SVM con kernel lineal y enfoque One-vs-One\n",
    "modelo = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Calcular las métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Imprimir las métricas de evaluación\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"ROC AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.26916805875125077\n",
      "R-squared: -0.08754771212626555\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Leer el DataFrame desde un archivo CSV\n",
    "df_historico = pd.read_csv('../Raw_Datasets/datos_historicos_deportes.csv')\n",
    "\n",
    "# Características (features) del modelo\n",
    "X = df_historico.drop('Deporte', axis=1)\n",
    "y = df_historico['Deporte']\n",
    "\n",
    "# Dividir los datos en un conjunto de entrenamiento (80%) y un conjunto de prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el modelo de regresión lineal\n",
    "modelo = LinearRegression()\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 72)\n",
      "(200, 72)\n",
      "(800,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "# Leer el DataFrame desde un archivo CSV\n",
    "df_historico = pd.read_csv('../Raw_Datasets/datos_historicos_deportes.csv')\n",
    "\n",
    "# Características (features) del modelo\n",
    "X = df_historico.drop('Deporte', axis=1)\n",
    "y = df_historico['Deporte']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(random_state=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(random_state=0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.96"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 -0.96\n",
      "MAE 0.49\n",
      "MAPE 923237923610952.0\n",
      "MSE 0.49\n",
      "RMSE 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"R2\", r2_score(y_test, y_pred))\n",
    "print(\"MAE\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MAPE\", mean_absolute_percentage_error(y_test, y_pred))\n",
    "print(\"MSE\", mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE\", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "folder = \"modelos_en_pkl\"\n",
    "\n",
    "# Asegúrate de que la carpeta exista. Si no existe, créala.\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "# Ruta completa del archivo donde se guardará el modelo\n",
    "filename = os.path.join(folder, \"DecisionTree.pkl\")\n",
    "\n",
    "# Guardar el modelo en el archivo\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
